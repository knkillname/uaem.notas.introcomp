{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Manipulación de Datos con Pandas y Vistazo a SciPy\n",
    "\n",
    "- *Autor*: [Dr. Mario Abarca](https://www.knkillname.org/)\n",
    "- *Objetivo*: Introducir la manipulación de datos estructurados con Pandas y explorar algunas funcionalidades clave de SciPy para cómputo científico avanzado.\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/knkillname/uaem.notas.introcomp/blob/master/cuadernos/12.PandasYSciPy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "¡Qué onda, futuros científicos de datos! Ya que dominamos NumPy para los números y Matplotlib para las gráficas chidas, es hora de conocer a **Pandas**, la navaja suiza para manipular datos tabulares. Y para rematar, le echaremos un ojo a **SciPy**, que nos dará superpoderes para cálculos científicos más especializados. ¡Abróchense los cinturones!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.1. Pandas: El Maestro de las Tablas de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pandas** es una biblioteca de Python que proporciona estructuras de datos de alto rendimiento y fáciles de usar, así como herramientas de análisis de datos. Es fundamental para cualquiera que trabaje con datos estructurados o tabulares (piensen en hojas de cálculo, bases de datos SQL, etc.).\n",
    "\n",
    "¿Por qué Pandas es tan popular?\n",
    "- **Estructuras de datos intuitivas:** Principalmente `Series` (1D) y `DataFrame` (2D).\n",
    "- **Manejo de datos faltantes:** Herramientas robustas para tratar con NaN (Not a Number).\n",
    "- **Funcionalidad de E/S (Entrada/Salida):** Fácil lectura y escritura de diversos formatos de archivo (CSV, Excel, SQL, JSON, etc.).\n",
    "- **Potentes operaciones de datos:** Agrupación, combinación, remodelación, filtrado, etc.\n",
    "- **Optimizado para rendimiento:** Aunque no tan rápido como NumPy para operaciones numéricas puras en arreglos homogéneos, Pandas está bien optimizado para muchas tareas de manipulación de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.1.1. Importando Pandas\n",
    "Por convención, Pandas se importa con el alias `pd`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np # A menudo se usa junto con NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.1.2. Estructuras de Datos de Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) Series:**\n",
    "Una `Serie` es un arreglo unidimensional etiquetado capaz de contener cualquier tipo de dato (enteros, cadenas, flotantes, objetos de Python, etc.). Las etiquetas de los ejes se conocen colectivamente como el **índice**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creando una Serie desde una lista\n",
    "datos_serie = [10, 20, 30, 40, 50]\n",
    "indices_serie = ['a', 'b', 'c', 'd', 'e']\n",
    "serie1 = pd.Series(data=datos_serie, index=indices_serie)\n",
    "print(\"Serie 1:\\n\", serie1)\n",
    "\n",
    "# Accediendo a elementos\n",
    "print(\"\\nElemento en índice 'c':\", serie1['c'])\n",
    "print(\"Primeros dos elementos:\\n\", serie1[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creando una Serie desde un diccionario\n",
    "datos_dict_serie = {'Matemáticas': 9.5, 'Física': 8.0, 'Química': 7.5}\n",
    "serie2 = pd.Series(datos_dict_serie)\n",
    "print(\"\\nSerie 2 (desde diccionario):\\n\", serie2)\n",
    "print(\"Calificación de Física:\", serie2['Física'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) DataFrame:**\n",
    "Un `DataFrame` es una estructura de datos tabular bidimensional, etiquetada y de tamaño variable, con columnas que pueden ser de diferentes tipos. Puedes pensarlo como una hoja de cálculo, una tabla SQL o un diccionario de Series.\n",
    "Es la estructura de datos más comúnmente utilizada en Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creación de DataFrames:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  **Desde un diccionario de listas o arreglos de NumPy:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_df = {\n",
    "    'Estudiante': ['Ana', 'Luis', 'Elena', 'Pedro'],\n",
    "    'Edad': [20, 22, 21, 23],\n",
    "    'Carrera': ['Física', 'Matemáticas', 'Química', 'Física']\n",
    "}\n",
    "\n",
    "df1 = pd.DataFrame(datos_df)\n",
    "print(\"DataFrame 1 (desde diccionario de listas):\\n\", df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  **Desde un arreglo de NumPy:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_np = np.array([\n",
    "    [1, 'Agua', 10.5],\n",
    "    [2, 'Sodio', 23.0],\n",
    "    [3, 'Cloro', 35.5]\n",
    "])\n",
    "\n",
    "df2 = pd.DataFrame(data=datos_np, columns=['ID', 'Elemento', 'MasaAtomica'])\n",
    "print(\"\\nDataFrame 2 (desde arreglo NumPy):\\n\", df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.1.3. Selección y Filtrado de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas ofrece varias formas de seleccionar y filtrar datos de un DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usaremos df1 para los ejemplos\n",
    "print(\"DataFrame original (df1):\\n\", df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) Selección de columnas:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nColumna 'Estudiante':\\n\", df1['Estudiante']) # Devuelve una Serie\n",
    "print(\"\\nColumnas 'Estudiante' y 'Carrera':\\n\", df1[['Estudiante', 'Carrera']]) # Devuelve un DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Selección de filas por etiqueta (índice) usando `.loc`:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero, asignemos un índice más significativo a df1\n",
    "df1_idx = df1.set_index('Estudiante')\n",
    "print(\"\\nDataFrame con índice 'Estudiante':\\n\", df1_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFila de 'Luis' usando .loc:\\n\", df1_idx.loc['Luis']) # Devuelve una Serie\n",
    "print(\"\\nFilas de 'Ana' y 'Pedro' usando .loc:\\n\", df1_idx.loc[['Ana', 'Pedro']]) # Devuelve un DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) Selección de filas por posición entera usando `.iloc`:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPrimera fila (posición 0) usando .iloc:\\n\", df1.iloc[0]) # Devuelve una Serie\n",
    "print(\"\\nPrimeras dos filas usando .iloc:\\n\", df1.iloc[0:2]) # Devuelve un DataFrame\n",
    "print(\"\\nFilas en posiciones 0 y 2, y columnas en posiciones 0 y 1:\\n\", df1.iloc[[0, 2], [0, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) Filtrado Booleano (condiciones):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nEstudiantes con Edad > 21:\\n\", df1[df1['Edad'] > 21])\n",
    "\n",
    "print(\"\\nEstudiantes de la carrera de 'Física':\\n\", df1[df1['Carrera'] == 'Física'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 12.1.1: Creación y Selección de Datos**\n",
    "1. Crea un DataFrame llamado `experimentos` con los siguientes datos:\n",
    "   - `ID_Muestra`: ['M01', 'M02', 'M03', 'M04', 'M05']\n",
    "   - `pH`: [7.0, 6.5, 8.1, 7.3, 6.8]\n",
    "   - `Temperatura_C`: [25, 30, 22, 28, 26]\n",
    "   - `Concentracion_mM`: [10, 15, 8, 12, 11]\n",
    "2. Muestra las primeras 3 filas del DataFrame.\n",
    "3. Selecciona y muestra solo las columnas `ID_Muestra` y `Concentracion_mM`.\n",
    "4. Filtra y muestra las muestras donde la `Temperatura_C` sea mayor a 25.\n",
    "5. Filtra y muestra las muestras donde el `pH` sea menor a 7.0 Y la `Concentracion_mM` sea mayor a 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Espacio para el Ejercicio 12.1.1\n",
    "# 1. Crear DataFrame 'experimentos'\n",
    "datos_experimentos = {\n",
    "    'ID_Muestra': ['M01', 'M02', 'M03', 'M04', 'M05'],\n",
    "    'pH': [7.0, 6.5, 8.1, 7.3, 6.8],\n",
    "    'Temperatura_C': [25, 30, 22, 28, 26],\n",
    "    'Concentracion_mM': [10, 15, 8, 12, 11]\n",
    "}\n",
    "experimentos = pd.DataFrame(datos_experimentos)\n",
    "print(\"1. DataFrame 'experimentos':\\n\", experimentos)\n",
    "\n",
    "# 2. Primeras 3 filas\n",
    "print(\"\\n2. Primeras 3 filas:\\n\", experimentos.head(3))\n",
    "\n",
    "# 3. Columnas 'ID_Muestra' y 'Concentracion_mM'\n",
    "print(\"\\n3. Columnas seleccionadas:\\n\", experimentos[['ID_Muestra', 'Concentracion_mM']])\n",
    "\n",
    "# 4. Muestras con Temperatura_C > 25\n",
    "print(\"\\n4. Muestras con Temperatura > 25°C:\\n\", experimentos[experimentos['Temperatura_C'] > 25])\n",
    "\n",
    "# 5. Muestras con pH < 7.0 Y Concentracion_mM > 10\n",
    "print(\"\\n5. Muestras con pH < 7.0 y Concentración > 10 mM:\\n\", \n",
    "      experimentos[(experimentos['pH'] < 7.0) & (experimentos['Concentracion_mM'] > 10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.1.4. Lectura y Escritura de Archivos CSV\n",
    "Pandas facilita enormemente trabajar con archivos CSV (Valores Separados por Comas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) Escribir un DataFrame a un archivo CSV:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usaremos el DataFrame 'experimentos' del ejercicio anterior\n",
    "experimentos.to_csv('datos_experimentos.csv', index=False) # index=False para no escribir el índice del DataFrame al archivo\n",
    "print(\"DataFrame 'experimentos' guardado en 'datos_experimentos.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Leer un archivo CSV a un DataFrame:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desde_csv = pd.read_csv('datos_experimentos.csv')\n",
    "print(\"\\nDataFrame leído desde 'datos_experimentos.csv':\\n\", df_desde_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** En Google Colab, el archivo CSV se guardará en el sistema de archivos temporal de la sesión. Si quieres descargarlo, puedes usar el panel de archivos a la izquierda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.1.5. Operaciones Básicas y Estadísticas Descriptivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DataFrame original (df_desde_csv):\\n\", df_desde_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) `df.info()`:** Muestra un resumen conciso del DataFrame, incluyendo el tipo de dato de cada columna y el uso de memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nInformación del DataFrame:\")\n",
    "df_desde_csv.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) `df.describe()`:** Genera estadísticas descriptivas de las columnas numéricas (conteo, media, desviación estándar, mínimo, máximo, cuartiles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nEstadísticas descriptivas:\\n\", df_desde_csv.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) `df.mean()`, `df.sum()`, `df.min()`, `df.max()`, etc.:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMedia de las temperaturas:\", df_desde_csv['Temperatura_C'].mean())\n",
    "print(\"Suma de las concentraciones:\", df_desde_csv['Concentracion_mM'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) `df.groupby()`:** Permite agrupar filas basándose en los valores de una o más columnas y luego aplicar funciones de agregación a cada grupo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agreguemos una columna de 'Tipo_Experimento' para demostrar groupby\n",
    "df_desde_csv['Tipo_Experimento'] = ['A', 'B', 'A', 'B', 'A']\n",
    "print(\"\\nDataFrame con 'Tipo_Experimento':\\n\", df_desde_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMedia de pH por Tipo_Experimento:\\n\", df_desde_csv.groupby('Tipo_Experimento')['pH'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 12.1.2: Operaciones y Estadísticas**\n",
    "Usando el DataFrame `experimentos` (o `df_desde_csv` si lo cargaste):\n",
    "1. Calcula la temperatura máxima y mínima registrada.\n",
    "2. Agrega una nueva columna llamada `pH_Acido` que sea `True` si el pH es menor a 7.0, y `False` en caso contrario.\n",
    "3. Cuenta cuántas muestras son de `Tipo_Experimento` 'A' y cuántas son de 'B' (puedes usar `groupby()` y `size()`, o `value_counts()`).\n",
    "4. Calcula la concentración promedio para las muestras con `pH_Acido` igual a `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Espacio para el Ejercicio 12.1.2\n",
    "df_ejercicio = df_desde_csv.copy() # Trabajaremos sobre una copia para no modificar el original\n",
    "\n",
    "# 1. Temperatura máxima y mínima\n",
    "temp_max = df_ejercicio['Temperatura_C'].max()\n",
    "temp_min = df_ejercicio['Temperatura_C'].min()\n",
    "print(f\"1. Temperatura Máxima: {temp_max}°C, Temperatura Mínima: {temp_min}°C\")\n",
    "\n",
    "# 2. Nueva columna 'pH_Acido'\n",
    "df_ejercicio['pH_Acido'] = df_ejercicio['pH'] < 7.0\n",
    "print(\"\\n2. DataFrame con columna 'pH_Acido':\\n\", df_ejercicio)\n",
    "\n",
    "# 3. Conteo de muestras por Tipo_Experimento\n",
    "conteo_tipo = df_ejercicio['Tipo_Experimento'].value_counts()\n",
    "# Alternativa: conteo_tipo = df_ejercicio.groupby('Tipo_Experimento').size()\n",
    "print(\"\\n3. Conteo de muestras por tipo:\\n\", conteo_tipo)\n",
    "\n",
    "# 4. Concentración promedio para muestras con pH_Acido == True\n",
    "concentracion_promedio_acido = df_ejercicio[df_ejercicio['pH_Acido'] == True]['Concentracion_mM'].mean()\n",
    "print(f\"\\n4. Concentración promedio para muestras ácidas: {concentracion_promedio_acido:.2f} mM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discusión 12.1: El Poder de Pandas**\n",
    "   - Imagina que tienes un archivo CSV con datos de mediciones de un sensor (tiempo, valor1, valor2) con miles de filas. ¿Qué operaciones de Pandas serían las primeras que aplicarías para entender los datos?\n",
    "   - Pide a tu asistente IA que te explique cómo Pandas maneja los datos faltantes (NaN) y qué estrategias comunes existen para tratarlos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.2. SciPy: Herramientas Científicas Avanzadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SciPy** (Scientific Python) es una biblioteca que se construye sobre NumPy y proporciona una gran colección de algoritmos y funciones para matemáticas, ciencia e ingeniería. Mientras NumPy se centra en la estructura de arreglo y operaciones fundamentales, SciPy ofrece funcionalidades más especializadas.\n",
    "\n",
    "SciPy está organizada en submódulos, cada uno dedicado a un área específica del cómputo científico. Algunos de los más importantes son:\n",
    "- `scipy.stats`: Funciones estadísticas y distribuciones de probabilidad.\n",
    "- `scipy.optimize`: Algoritmos de optimización (minimización, ajuste de curvas).\n",
    "- `scipy.integrate`: Integración numérica.\n",
    "- `scipy.linalg`: Álgebra lineal extendida (más allá de lo básico de NumPy).\n",
    "- `scipy.signal`: Procesamiento de señales.\n",
    "- `scipy.interpolate`: Interpolación.\n",
    "- `scipy.fft`: Transformadas de Fourier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2.1. `scipy.stats`: Estadísticas y Distribuciones\n",
    "Este módulo es muy útil para trabajar con distribuciones de probabilidad y realizar pruebas estadísticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt # Para graficar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) Distribución Normal (Gaussiana):**\n",
    "Podemos generar números aleatorios de una distribución normal, calcular su función de densidad de probabilidad (PDF) y su función de distribución acumulada (CDF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros de la distribución normal: media (loc) y desviación estándar (scale)\n",
    "media = 0\n",
    "desv_est = 1\n",
    "\n",
    "# Generar 1000 muestras aleatorias\n",
    "muestras_normales = stats.norm.rvs(loc=media, scale=desv_est, size=1000)\n",
    "\n",
    "# Graficar el histograma de las muestras\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.hist(muestras_normales, bins=30, density=True, alpha=0.6, label='Histograma de muestras')\n",
    "\n",
    "# Graficar la PDF teórica\n",
    "x_normal = np.linspace(-4, 4, 100)\n",
    "pdf_normal = stats.norm.pdf(x_normal, loc=media, scale=desv_est)\n",
    "plt.plot(x_normal, pdf_normal, 'r-', lw=2, label='PDF teórica')\n",
    "\n",
    "plt.title('Distribución Normal')\n",
    "plt.xlabel('Valor')\n",
    "plt.ylabel('Densidad')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Calcular la probabilidad de que una variable aleatoria sea menor que 1 (CDF)\n",
    "prob_menor_que_1 = stats.norm.cdf(1, loc=media, scale=desv_est)\n",
    "print(f\"P(X < 1) para una N(0,1): {prob_menor_que_1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Prueba de hipótesis simple (t-test de una muestra):**\n",
    "Supongamos que tenemos un conjunto de mediciones y queremos probar si la media de estas mediciones es significativamente diferente de un valor conocido (hipótesis nula)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de ejemplo: mediciones de la longitud de un componente (en cm)\n",
    "mediciones_longitud = np.array([10.1, 9.8, 10.3, 10.0, 9.9, 10.2, 9.7, 10.1, 10.0, 9.9])\n",
    "media_conocida = 10.0 # Hipótesis nula: la media verdadera es 10.0 cm\n",
    "\n",
    "t_statistic, p_value = stats.ttest_1samp(mediciones_longitud, media_conocida)\n",
    "\n",
    "print(f\"Estadístico t: {t_statistic:.4f}\")\n",
    "print(f\"Valor p: {p_value:.4f}\")\n",
    "\n",
    "alpha = 0.05 # Nivel de significancia\n",
    "if p_value < alpha:\n",
    "    print(f\"Como p ({p_value:.4f}) < alpha ({alpha}), rechazamos la hipótesis nula.\")\n",
    "    print(\"La media de las mediciones es significativamente diferente de 10.0 cm.\")\n",
    "else:\n",
    "    print(f\"Como p ({p_value:.4f}) >= alpha ({alpha}), no podemos rechazar la hipótesis nula.\")\n",
    "    print(\"No hay evidencia suficiente para decir que la media es diferente de 10.0 cm.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2.2. `scipy.optimize`: Optimización y Ajuste de Curvas\n",
    "Este módulo ofrece herramientas para encontrar mínimos de funciones, resolver ecuaciones y ajustar curvas a datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) Encontrar el mínimo de una función:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# Definimos una función cuadrática simple: f(x) = (x-3)^2\n",
    "def funcion_cuadratica(x):\n",
    "    return (x - 3)**2\n",
    "\n",
    "# Valor inicial para la búsqueda del mínimo\n",
    "x_inicial = 0.0\n",
    "\n",
    "resultado_min = minimize(funcion_cuadratica, x_inicial)\n",
    "\n",
    "print(\"Resultado de la minimización:\", resultado_min)\n",
    "print(f\"El mínimo de la función se encuentra en x = {resultado_min.x[0]:.4f}\")\n",
    "print(f\"El valor mínimo de la función es f(x) = {resultado_min.fun:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Ajuste de curvas (Curve Fitting):**\n",
    "Supongamos que tenemos datos experimentales que creemos que siguen un modelo funcional, y queremos encontrar los parámetros del modelo que mejor se ajustan a los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Datos experimentales (simulados): crecimiento exponencial y = a * exp(b*x)\n",
    "x_datos = np.array([0.0, 1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "y_datos = np.array([1.0, 2.7, 7.4, 20.1, 54.6, 148.4]) # Aproximadamente exp(x)\n",
    "\n",
    "# Definimos la función del modelo\n",
    "def modelo_exponencial(x, a, b):\n",
    "    return a * np.exp(b * x)\n",
    "\n",
    "# Realizamos el ajuste de curva\n",
    "params_opt, params_cov = curve_fit(modelo_exponencial, x_datos, y_datos, p0=[1,1]) # p0 son valores iniciales para a y b\n",
    "\n",
    "a_opt, b_opt = params_opt\n",
    "print(f\"Parámetros óptimos: a = {a_opt:.4f}, b = {b_opt:.4f}\")\n",
    "\n",
    "# Graficamos los datos y la curva ajustada\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(x_datos, y_datos, label='Datos experimentales')\n",
    "x_ajuste = np.linspace(0, 5, 100)\n",
    "y_ajuste = modelo_exponencial(x_ajuste, a_opt, b_opt)\n",
    "plt.plot(x_ajuste, y_ajuste, 'r-', label=f'Ajuste: y = {a_opt:.2f} * exp({b_opt:.2f}*x)')\n",
    "plt.title('Ajuste de Curva Exponencial')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 12.2.1: Explorando SciPy**\n",
    "1. **Distribución de Poisson:** La distribución de Poisson modela el número de eventos que ocurren en un intervalo fijo de tiempo o espacio, si estos eventos ocurren con una tasa media conocida e independientemente del tiempo desde el último evento (ej. número de partículas alfa emitidas por una fuente radiactiva en un segundo).\n",
    "   - Investiga la función `stats.poisson` en SciPy.\n",
    "   - Si una fuente emite en promedio $\\lambda = 3$ partículas por segundo, genera 1000 muestras aleatorias de esta distribución.\n",
    "   - Grafica un histograma de tus muestras.\n",
    "   - Calcula la probabilidad de observar exactamente 2 partículas en un segundo usando `stats.poisson.pmf()` (Función de Masa de Probabilidad).\n",
    "   - Calcula la probabilidad de observar 2 o menos partículas en un segundo usando `stats.poisson.cdf()`.\n",
    "\n",
    "2. **Optimización (Opcional Avanzado):** La función de Rosenbrock es una función no convexa utilizada como prueba de rendimiento para algoritmos de optimización: $f(x, y) = (a-x)^2 + b(y-x^2)^2$. Usualmente $a=1$ y $b=100$.\n",
    "   - Define la función de Rosenbrock en Python.\n",
    "   - Usa `scipy.optimize.minimize` para encontrar su mínimo. El mínimo global está en $(x,y) = (a, a^2)$, que para $a=1$ es $(1,1)$ donde $f(1,1)=0$.\n",
    "   - Prueba con diferentes puntos iniciales (ej. `x0 = [0,0]` o `x0 = [-1, 2]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Espacio para el Ejercicio 12.2.1\n",
    "\n",
    "# 1. Distribución de Poisson\n",
    "lambda_poisson = 3\n",
    "muestras_poisson = stats.poisson.rvs(mu=lambda_poisson, size=1000)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.hist(muestras_poisson, bins=range(0, np.max(muestras_poisson) + 2), density=True, alpha=0.7, edgecolor='black', align='left')\n",
    "plt.title(f'Distribución de Poisson ($\\lambda$={lambda_poisson})')\n",
    "plt.xlabel('Número de eventos')\n",
    "plt.ylabel('Probabilidad / Frecuencia relativa')\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "prob_exact_2 = stats.poisson.pmf(2, mu=lambda_poisson)\n",
    "print(f\"Probabilidad de observar exactamente 2 partículas: {prob_exact_2:.4f}\")\n",
    "\n",
    "prob_2_o_menos = stats.poisson.cdf(2, mu=lambda_poisson)\n",
    "print(f\"Probabilidad de observar 2 o menos partículas: {prob_2_o_menos:.4f}\")\n",
    "\n",
    "# 2. Optimización de la función de Rosenbrock (Opcional Avanzado)\n",
    "def rosenbrock(p):\n",
    "    a = 1.0\n",
    "    b = 100.0\n",
    "    x, y = p\n",
    "    return (a - x)**2 + b * (y - x**2)**2\n",
    "\n",
    "x0_1 = [0.0, 0.0]\n",
    "resultado_rosen1 = minimize(rosenbrock, x0_1, method='Nelder-Mead') # Nelder-Mead es un método común que no requiere gradientes\n",
    "print(f\"\\nResultado de minimizar Rosenbrock desde {x0_1}:\")\n",
    "print(f\"  Punto mínimo encontrado: {resultado_rosen1.x}\")\n",
    "print(f\"  Valor mínimo encontrado: {resultado_rosen1.fun:.4e}\") # Usamos notación científica para valores pequeños\n",
    "\n",
    "x0_2 = [-1.0, 2.0]\n",
    "resultado_rosen2 = minimize(rosenbrock, x0_2, method='Nelder-Mead')\n",
    "print(f\"\\nResultado de minimizar Rosenbrock desde {x0_2}:\")\n",
    "print(f\"  Punto mínimo encontrado: {resultado_rosen2.x}\")\n",
    "print(f\"  Valor mínimo encontrado: {resultado_rosen2.fun:.4e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discusión 12.2: El Universo de SciPy**\n",
    "   - SciPy es vasto. Pide a tu asistente IA que te dé un ejemplo de cómo se podría usar `scipy.integrate` para calcular el área bajo una curva (una integral definida) de una función que no se puede integrar analíticamente fácilmente (ej. $e^{-x^2}$).\n",
    "   - ¿En qué tipo de problemas científicos o de ingeniería crees que los módulos de SciPy como `signal` (procesamiento de señales) o `fft` (transformada rápida de Fourier) serían indispensables?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
